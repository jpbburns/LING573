Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5768010575123828
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5696470172955226
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5728167726406408
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.569240478536335
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5651151241689517
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.567757056787051
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5714728604975896
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5706186294893035
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5739847136287811
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5880018484513961
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6360923445101173
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5920654881222255
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5922190778187988
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.6491766605175564
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5871153387367954
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5816826368458148
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.643882390477259
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7408474129870317
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.851203454994715
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.8467138459802741
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7628084939820643
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.8012701713258132
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 1.0094059424737205
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.946558782171316
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7517156833032619
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.664619976012033
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6154816741788931
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5665033102506271
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.564090064591755
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5707490183144988
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5663281479411456
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5709083423960418
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.56908068802347
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5679754504811382
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5634594594319489
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5689644484334513
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5835558328193438
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5708069590317076
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6691945953339502
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.580345007863511
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5777749488813524
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5918001040748617
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5812560688359002
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5788329101791375
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7553365260555852
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7633610694033784
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7755460480401821
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.8181488225995888
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7295113741864594
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7916471685561252
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7182036234427288
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7810699499350883
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.8448075896324349
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7756952837916872
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5715741244715868
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5673491646976242
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5675822823444521
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5671451089436274
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5738838742769978
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5669409782782088
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5694728220227013
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5720801794019731
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.570024257428503
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.573437087284579
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5765573281756153
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5807010600097459
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5766720375221089
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5736965544723918
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5757680834679678
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.575509550035438
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5700097527380852
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5765429872982736
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7177660381168981
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7026436763840103
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7924196397816902
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.6591111001849755
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.72000872127196
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.8256331507674349
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6533913139915071
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7801590807176599
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7034903766922322
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5672908709240249
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5689935107553165
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5730765212736703
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5710820999420001
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5737253774429144
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5735956648370591
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5796179811219002
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5648517147633325
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.572686854892218
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6165687995806456
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6323378625149946
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6237016238558246
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.617573693171384
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6737749688743905
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6635991106113425
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6488072129183389
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6778366915022576
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6663593011685816
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.9406180331854048
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.8083585599829308
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.8378302189056785
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.9839976261507019
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.9847283581240057
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.8339925668497962
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8968918745170085
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6866108576016273
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 1.11859031726264
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5743591045665761
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5743159177253313
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5731053742260299
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5658753951508008
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5666638281415667
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5655246275683148
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5670867925325391
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5697340943064093
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5693421409209002
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5839948786031897
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5919816959332507
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6131398429516248
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5840939718558675
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6144464456053662
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6299143254734905
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5987861461710473
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6099898649566756
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5994347583299757
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7561679620416217
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7375814859155763
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7454977104994729
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7770796752521807
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6934763584104339
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7868178031536416
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8510868889497665
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8221308415138336
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.7213739072634014
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5663135484241153
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.571574124417269
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5767723891528163
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5675531470840779
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5645442485688026
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5776175191050389
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.571400516196408
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5668097137835266
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5706041399993012
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5756531943642169
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5802452744942276
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5836408345378595
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5900231548949385
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5813982929077192
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6151323096125108
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5784471215485495
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5776890843641617
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6024752544585951
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7681118772940387
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7567690882487791
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6827708973623671
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6689227310205437
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7322489320117539
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.8747526596452828
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6779220684520484
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8745163356403277
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8609578601916389
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5825774124900743
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5703287691771108
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.574445467909471
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5772882085895273
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5730765203793462
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.578861476092539
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.583300750266246
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5774886802748965
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5711979077325163
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6576040993218674
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6194451327811556
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.8426419531957531
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6421980602552019
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6969134040815215
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7511545408698521
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6109649822242174
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7181921110904115
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6703549566174478
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7087126771329029
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7643244106688806
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6707495158307207
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.850309374043006
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6641221888832047
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7989658398975448
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7494024015089105
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.9055613321089752
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.8885845254698792
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.571241330240417
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5710965760676724
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5753371294413486
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.573710965007388
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5653052871828264
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5780610744369824
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.59075136945463
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5719211811624612
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5732351970548146
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5993795846492446
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6157637039671356
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6374426947749849
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.579018568364365
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5994761353820169
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6110326405581666
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6023929096730346
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.639747258133872
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7338054461250388
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.621829698626394
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.817188227279945
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 1.0168566778625
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.8280729586792984
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7587112872709889
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.8862833217629964
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7911770534070467
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7975987042880607
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.8366946056949963
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5708504105494733
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5734370867478922
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5844194470694226
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5771592958864781
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5689063187654015
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5757393622880065
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.568964447742703
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5728600713481721
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5840231913612626
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5828611815117696
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5828611810264576
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5982197611734663
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5907233781029918
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5798461657326902
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5937249340107275
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5898970244626597
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5826199864291994
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.599200234536031
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7598111141826923
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7377720216443691
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.8518831049568991
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7569875612544515
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6888829565659608
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7245531409107747
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7024671518821223
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7622446712684102
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7592995115725937


Best Model -- Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5634594594319489
