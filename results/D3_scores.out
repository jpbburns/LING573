Results on hyperparameter tuning

Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5729177999705913
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5672617207011796
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5688917865785958
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5749346151077928
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5707055582796424
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5701547822659315
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5697486068881538
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5695308929866528
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5698356684900805
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6254622059464865
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6355071688964329
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7535173072754549
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.6290211648163321
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7010179745976579
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.6907168004997197
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5943651592847833
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6051043691932673
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6245097246482801
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.8832837302631501
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.9412155523812331
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.8515142194392884
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7578826428604726
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.8285121596844124
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.9346925988923442
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.8062283319093643
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.8203791186133647
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.809268338706511
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.566795127324508
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5686737454563391
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5663427473998612
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.566663827888496
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5706910713188014
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5693276192041454
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5735524203069466
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5669701445953664
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5732928880022209
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5797178234821505
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5904293852014836
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7228394635789367
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.583810803162891
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5869181540057068
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.619992127658404
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5787614873786399
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5793897062180648
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.576313494885274
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7037723840986114
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6965455367390498
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.8404215490391724
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.6239534403886111
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.8251423198342577
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7690692676644207
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.821788844306903
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6924980340615176
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7513746468276142
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.568920852091673
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5665179046933975
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.572123534093993
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.569574441882406
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5697486061001844
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5753227591956795
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5634007630872895
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5691387990872336
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.568586505208719
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5720512738327254
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.572556907150576
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.5775888912573722
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5746037676097591
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5749921345924012
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.5858183422962691
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5719356388545657
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5778321856661357
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.5767723890105558
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6219094695128407
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.6367938457093394
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 1	 RMSE: 0.7458303487584297
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7200431692904973
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.7848398128589623
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 1	 RMSE: 0.8464892287364092
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.7269113814456939
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.6539984133359082
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 1	 RMSE: 0.8640445311023798
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.574258331267372
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5738406521614823
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5683828928176532
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5759834392878234
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5696905576240607
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5769873706265424
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5737253764671421
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5719934597723557
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.568760971787017
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5979985886650864
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7838911364177937
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6893388763255744
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6252109981087497
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7083275924212395
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6599510124880138
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6464965797625964
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.7754820806498777
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.656018022601095
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.838639021296754
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.8450033011515183
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7503285699683482
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.766182716960655
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.8933450079366375
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.8420628548251213
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.72562498271703
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8680541288749776
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8377117919252781
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5686301264851743
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5654076567279674
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5680336744235231
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5681064461105759
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.569371184074623
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5697921390031789
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.569458303719783
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5676551109792617
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5671596861596786
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5895184774419193
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5904573914166351
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7685745854295918
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5870167544858258
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5982197613958882
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5870730899075735
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5867349955983728
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6017200060142944
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.7134217829635697
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.9106870802426202
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6795300223155315
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.7812075472919339
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7535392521392326
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7062000214451828
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.7929932867445585
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.9853243008985518
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8927247096264083
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.7278434511625023
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5660360903952896
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5675240110656276
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5746613199307004
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5664741201761712
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5695454099406128
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5746900936955149
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5615633976283978
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5705171945549292
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5717042959736331
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5778751091560388
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.5803165145239156
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.59240054053017
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5813982923711766
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.5804732120421063
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.586368505813881
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5825774133148298
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5748770903798252
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5829746505673931
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.8885286965415251
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.6443573201594296
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 2	 RMSE: 0.9823830530884182
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.8499300778707904
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 0.6994357794945344
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 2	 RMSE: 1.0352689078684183
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.7520565650501813
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.6456391656541427
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.8369317305745476
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5828186246114984
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5727301639271136
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5722969227395411
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5868618027322847
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5789757289678069
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5736100778606948
Epochs: 2, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.585154637044285
Epochs: 2, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5711400059379093
Epochs: 2, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5802595216858565
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6179885717169614
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.72299957887942
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6991047187027423
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6222151639270627
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6762858410453241
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6304128929475042
Epochs: 2, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6379742591334147
Epochs: 2, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7091208708449908
Epochs: 2, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7112397049904646
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.620698505935523
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.626294439214613
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.782339157673191
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7160245710939194
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.807908402803149
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7812816276330065
Epochs: 2, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6830251457520694
Epochs: 2, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.9477285053553104
Epochs: 2, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.8957111462376695
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5722680279105822
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.574891471708199
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5721524357494662
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5775316294139519
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.575997792100022
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5712992208724718
Epochs: 4, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5731919259649579
Epochs: 4, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.573984712711403
Epochs: 4, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5845609007283766
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.6071912950748928
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5962955746524958
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7206744285148723
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5891537191415146
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6441648227105664
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6233303406016419
Epochs: 4, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6250522878035488
Epochs: 4, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6521500623446556
Epochs: 4, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6400315153651911
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7827195186439052
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.8166720731298693
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.8328120111598794
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.8106973845547977
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7546794834216133
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.87199788402088
Epochs: 4, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7949301877709486
Epochs: 4, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.770100624018341
Epochs: 4, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7663337758286787
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5693857036840994
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5682228605746811
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5831164551782202
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5773598126860409
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5739270924844758
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5794039760631916
Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5830597366259749
Epochs: 8, Batch Size: 8, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5708504100388428
Epochs: 8, Batch Size: 16, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5782898734170387
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5849991931136166
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5840798163214721
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.5902333077827281
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5825774124224021
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5941147183295434
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.5979294536902473
Epochs: 8, Batch Size: 4, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5834991566365015
Epochs: 8, Batch Size: 8, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.5910312140894561
Epochs: 8, Batch Size: 16, Learning Rate: 2e-05, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6150382166057866
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7459190270659559
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.8485768477035529
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.2, Num Hidden Layers: 3	 RMSE: 0.7365494946844535
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.7085259954482819
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.6740080770620291
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.3, Num Hidden Layers: 3	 RMSE: 0.8390923979905281
Epochs: 8, Batch Size: 4, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7114256742619217
Epochs: 8, Batch Size: 8, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.7901522798837948
Epochs: 8, Batch Size: 16, Learning Rate: 2e-06, Dropout Probability: 0.4, Num Hidden Layers: 3	 RMSE: 0.6805269890387233


Best Model -- Epochs: 8, Batch Size: 4, Learning Rate: 0.0002, Dropout Probability: 0.4, Num Hidden Layers: 2	 RMSE: 0.5615633976283978
